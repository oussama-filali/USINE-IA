# Configuration et Scripts Supabase

## ðŸš€ Configuration Initiale

### 1. CrÃ©er la table newsletter

1. Aller sur [supabase.com](https://supabase.com)
2. Ouvrir votre projet
3. Aller dans **SQL Editor**
4. Copier/coller le contenu de `create-newsletter-table.sql`
5. Cliquer sur **Run**

### 2. CrÃ©er la table articles (optionnel)

Si vous voulez stocker les articles dans Supabase:

1. Dans **SQL Editor**
2. Copier/coller le contenu de `create-articles-table.sql`
3. Cliquer sur **Run**

### 3. RÃ©cupÃ©rer vos clÃ©s API

1. Aller dans **Settings** â†’ **API**
2. Copier:
   - `Project URL` â†’ SUPABASE_URL
   - `anon public` key â†’ SUPABASE_ANON_KEY
3. Mettre Ã  jour le fichier `api/.env`:

```env
SUPABASE_URL=https://votre-projet.supabase.co
SUPABASE_ANON_KEY=votre-cle-anon
PORT=3001
```

## ðŸ“° Sources d'Articles IA Gratuits

### APIs Gratuites RecommandÃ©es:

1. **NewsAPI.org** (100 requÃªtes/jour gratuit)
   - https://newsapi.org/
   - Recherche: "artificial intelligence", "AI", "machine learning"

2. **RSS Feeds IA** (gratuit illimitÃ©):
   - OpenAI Blog: https://openai.com/blog/rss.xml
   - Google AI Blog: https://ai.googleblog.com/feeds/posts/default
   - MIT Technology Review AI: https://www.technologyreview.com/topic/artificial-intelligence/feed/
   - Towards Data Science: https://towardsdatascience.com/feed

3. **Reddit API** (gratuit):
   - r/artificial
   - r/MachineLearning
   - r/OpenAI

4. **Dev.to API** (gratuit illimitÃ©):
   - https://dev.to/api/articles?tag=ai

## ðŸ¤– Script d'import automatique

Pour automatiser l'import d'articles, voir le fichier `import-articles.js`

### Utilisation:

```bash
cd api
node import-articles.js
```

Vous pouvez aussi crÃ©er un cron job pour importer automatiquement tous les jours.

## ðŸ”’ SÃ©curitÃ©

- Les clÃ©s Supabase `anon` sont publiques (safe pour frontend)
- Les politiques RLS protÃ¨gent les donnÃ©es sensibles
- Ne jamais commit le fichier `.env` avec les vraies clÃ©s
